# UFC-2026 Frontend Codebase Analysis

## ğŸš€ Project Status Overview (Last Updated: 2026-02-26)

### Current Implementation Status:
- **âœ… Core UI/UX Framework**: Complete with fixed-aspect container system, Material Design 3, and custom shadow system
- **âœ… Four-State Workflow System**: Fully implemented with 7-state Pinia store (`idle` â†’ `collecting_conditions` â†’ `selecting_clinic` â†’ `collecting_requirements` â†’ `patching_route` â†’ `completed` â†’ `error`)
- **âœ… API Service Layer**: Complete HTTP client with error handling for all smart triage endpoints
- **âœ… NavigationView Integration**: Workflow system fully integrated with voice-only interaction interface
- **âœ… Backend Connectivity**: API client fully functional. STT APIéŸ³é¢‘æ ¼å¼å…¼å®¹æ€§å·²ä¿®å¤ï¼ˆæ”¯æŒWAVã€WebMã€MP4ã€OGG/Opusæ ¼å¼è½¬æ¢ï¼‰ã€‚CORSé—®é¢˜å·²è§£å†³ï¼Œæ‰€æœ‰ç«¯ç‚¹å¯è®¿é—®ã€‚
- **âœ… Voice Integration Framework**: Complete implementation with voice recording (`useVoiceRecorder`). STT APIéŸ³é¢‘æ ¼å¼å…¼å®¹æ€§å·²ä¿®å¤ï¼Œæ”¯æŒå¤šæ ¼å¼è½¬æ¢ã€‚Skeletonæ¶ˆæ¯å’Œæµå¼æ–‡æœ¬æ˜¾ç¤ºå·²å®ç°ã€‚é›†æˆåˆ°NavigationView.vueã€‚è¯­éŸ³è¾“å…¥åˆ°å·¥ä½œæµå®Œæ•´æµç¨‹å·²éªŒè¯ã€‚
- **â³ MedicalView Adaptation**: Navigation workflow complete, medical consultation page needs similar integration
- **â³ Testing & Validation**: Manual testing guide available, automated tests not yet implemented

### Key Technical Achievements:
1. **Voice-First Design**: Pure voice interaction with no text input dependencies
2. **Type-Safe Data Flow**: JSDoc type definitions matching backend Pydantic models
3. **Route Processing Pipeline**: Four-stage path generation and modification system
4. **Error Recovery**: Voice command "é‡æ–°å¼€å§‹" to restart workflow from any state
5. **Environment Configuration**: `.env`-based API endpoint management

### Next Priority Tasks:
1. **âœ… Install ffmpeg** - Completed, required for STT API audio format conversion (WebM â†’ WAV, MP4 â†’ WAV, etc.)
2. **Test complete voice interaction workflow** with actual microphone input
3. **Integrate actual streaming animation** for recognized text display
4. Connect text-to-speech with `/api/voice/tts` endpoint
5. Adapt workflow system for MedicalView.vue
6. Implement WebSocket for real-time voice streaming
7. Add error handling and user feedback improvements

### âœ… Recently Completed:
- **STT API audio format compatibility** - Implemented backend audio format detection and conversion using `pydub` and `python-magic`
- **CORS issue resolution** - Enhanced CORS middleware configuration, fixed `select_clinic` endpoint access
- **Voice input workflow integration** - Complete voice-to-workflow pipeline with duplicate message prevention
- **Frontend-backend integration** - Full four-state workflow system with voice interaction

## 2. Application Scenario & Problem Statement

**Application**: UFC-2026 Frontend - Hospital Intelligent Assistant System

**Primary Users**: Hospital patients, visitors, and potentially medical staff

**Core Problem Solved**: This application provides an intelligent hospital navigation and medical consultation system that helps users:
- Navigate through hospital facilities using voice interaction
- Access medical information and preliminary consultation
- Use facial recognition for login/authentication
- Interact with AI assistants for both navigation and medical guidance

**User Journey**:
1. **Login Page** (`HomeView.vue`): Facial recognition login with camera access
2. **Navigation Assistant** (`NavigationView.vue`): Hospital wayfinding and route guidance
3. **Medical Assistant** (`MedicalView.vue`): Medical consultation and health advice
4. **Settings** (`SettingsView.vue`): App configuration and preferences

## 3. Features & Functionalities

### Core Features:
1. **Four-State Workflow System**:
   - **Hospital Navigation Workflow**: `collecting_conditions` â†’ `selecting_clinic` â†’ `collecting_requirements` â†’ `patching_route`
   - **Automatic State Transitions**: Symptom analysis â†’ Clinic selection â†’ Requirement collection â†’ Route optimization
   - **Voice-First Interaction**: Pure voice interface with no text input dependencies
   - **Route Processing Pipeline**: Four-stage route processing: 1) Base path (`entrance â†’ registration_center â†’ <xxx_clinic> â†’ pharmacy â†’ exit`) 2) Original route generation (replace clinic placeholder) 3) Patch application (apply requirement-based modifications) 4) Route validation (continuity checking)
   - **Error Recovery**: Voice command "é‡æ–°å¼€å§‹" to restart workflow from any state

2. **Voice Interaction System**:
   - Long-press (250ms) FAB button for voice input
   - Visual feedback with `VoiceOverlay` and `ListeningIndicator`
   - Custom audio waveform animations and pulse rings

3. **Conversation Interface**:
   - Four-layer message bubble architecture
   - Assistant vs. User message differentiation
   - Scrollable conversation history
   - Mock conversation data for both navigation and medical modes

3. **Facial Recognition Login**:
   - Camera access via `useCamera` composable
   - Animated scanning effects with chaos motion animations
   - Tech-themed visual design with decorative elements

4. **Navigation System**:
   - Intelligent wayfinding assistant
   - Route guidance and directions
   - Hospital-specific navigation

5. **Medical Consultation**:
   - AI-powered medical advice
   - Symptom analysis and preliminary guidance
   - Medical disclaimer integration

6. **Settings Management**:
   - Voice wakeup toggle
   - Continuous conversation mode
   - Volume and speech rate controls
   - Privacy policy and about sections

### UI/UX Features:
- Fixed aspect ratio container system (300Ã—600px default, 332Ã—774.66px planned)
- Responsive overflow detection with `useViewportOverflow`
- Material Design 3 with custom shadows and animations
- Custom color system with primary color `#4252b3`
- Inter font family with consistent typography scale

## 4. Architecture & Design Patterns

### Component Architecture:
1. **Four-Layer Message Bubble System**:
   - `MessageBubble` (Router): Routes based on `name` prop (`'assistant'`/`'user'`)
   - `BasicMessageBubble` (Generic): Core implementation with `isAssistant` prop
   - `AssistantMessageBubble`: Left-aligned, blue-themed assistant messages
   - `UserMessageBubble`: Right-aligned, gray-themed user messages (independent implementation)

2. **Layout Architecture**:
   - `FixedAspectContainer`: Root container for all pages with fixed dimensions
   - `AppTopBar`: Dynamic title based on current route
   - `AppBottomNav`: Bottom navigation with FAB microphone button
   - `ConversationList`: Scrollable message container

3. **Composables Pattern**:
   - `useLongPress(250)`: Handles 250ms long-press logic for voice input
   - `useViewportOverflow()`: Detects content overflow and adjusts layout
   - `useCamera()`: Manages camera access and video streaming

### Routing Structure:
- `/` â†’ `HomeView` (Facial recognition login)
- `/nav_page` â†’ `NavigationView` (Navigation assistant)
- `/doctor_page` â†’ `MedicalView` (Medical assistant)
- `/settings` â†’ `SettingsView` (App settings)
- `/chat` â†’ Redirects to `/nav_page`

### State Management:
- **Pinia Workflow System**: Complete 7-state state machine (`idle` â†’ `collecting_conditions` â†’ `selecting_clinic` â†’ `collecting_requirements` â†’ `patching_route` â†’ `completed` â†’ `error`)
- **Centralized State Management**: `useWorkflowStore()` in `/src/stores/workflow.js` with computed properties for all states
- **API Service Layer**: `useApiStore()` in `/src/stores/api.js` for backend communication with standardized error handling
- **Dynamic Message Management**: Workflow-driven conversation history replacing hardcoded data
- **Type-Safe Data Flow**: JSDoc type definitions matching backend Pydantic models in `/src/types/workflow.js`

## 5. Technology Stack

### Core Technologies:
- **Vue 3.5.25** (Composition API)
- **Vuetify 3.12.0** (Material Design 3)
- **Tailwind CSS v4.2.0** (Latest version)
- **Vite 7.3.1** (Build tool)
- **Vue Router 5.0.3**
- **Pinia 3.0.4** (Implemented with workflow state management stores)

### Development Tools:
- **Material Design Icons** (`@mdi/font 7.4.47`)
- **Vite plugins**: Vue, Vuetify, Tailwind CSS
- **Alias configuration**: `@` points to `./src`

### Design System:
- **Primary Color**: `#4252b3` (Deep blue)
- **Background**: `#f6f6f8` (Light gray)
- **Font**: Inter (sans-serif)
- **Spacing**: 4px base unit system
- **Shadows**: Custom values for enhanced Material Design 3 effects
- **Border Radius**: Consistent scale (4px, 8px, 16px, full)

## 6. Backend Integration

### Current State:
- **âœ… Workflow System Implementation**: Complete four-state workflow with API service layer (`/src/stores/api.js`)
- **âœ… State Management**: Pinia workflow store with 7-state machine and automatic transitions
- **âœ… Environment Configuration**: `.env` and `.env.development` with `VITE_API_BASE_URL=http://localhost:8000/api`
- **ğŸ”„ Voice Interaction Framework**: UI ready with long-press (250ms) FAB button, but actual STT/TTS API integration pending
- **ğŸ”„ Backend API Integration**: API client implemented but untested with running backend server
- **â³ Real-time Communication**: WebSocket for voice streaming not yet implemented
- **â³ Authentication**: JWT token management for secure API calls pending

### Expected Integration Points (based on documentation):
1. **Smart Triage API**: `/api/triager/get_route_patch/` for navigation
2. **Face Recognition API**: Medical records and authentication
3. **Voice Interaction API**: Speech-to-text and text-to-speech
4. **Navigation API**: Map data and pathfinding

### Smart Triage API æ¥å£è¯¦æƒ…ï¼ˆåŸºäº `backend/src/router/triager.py`ï¼‰ï¼š

åç«¯æ™ºèƒ½åˆ†è¯Šç³»ç»Ÿæä¾›äº†ä»¥ä¸‹ RESTful API ç«¯ç‚¹ï¼Œæ‰€æœ‰ç«¯ç‚¹å‡ä»¥ `/api/triager/` ä¸ºå‰ç¼€ï¼š

#### 1. `POST /get_route_patch/` - è·å–è·¯çº¿ä¿®æ”¹æ–¹æ¡ˆ
**åŠŸèƒ½**ï¼šæ ¹æ®ç”¨æˆ·è¾“å…¥çš„éœ€æ±‚ï¼Œç”Ÿæˆå¯¹åŸè·¯çº¿çš„ä¿®æ”¹æ–¹æ¡ˆï¼ˆé›†æˆå¤šæ­¥å·¥ä½œæµï¼‰ã€‚
**è¯·æ±‚ä½“**ï¼š
```json
{
  "user_input": "å­—ç¬¦ä¸²ï¼Œç”¨æˆ·éœ€æ±‚æè¿°",
  "origin_route": [
    {"this": "èµ·ç‚¹ä½ç½®ID", "next": "ä¸‹ä¸€ä½ç½®ID"},
    ...
  ],
  "online_model": true
}
```
**å“åº”**ï¼š
- æˆåŠŸï¼š`{"success": true, "data": "ä¿®æ”¹åçš„è·¯çº¿JSON"}`
- å¤±è´¥ï¼š`{"success": false, "error": "é”™è¯¯ä¿¡æ¯"}`

#### 2. `POST /collect_conditions/` - æ”¶é›†ç—‡çŠ¶ä¿¡æ¯
**åŠŸèƒ½**ï¼šä»ç”¨æˆ·è¾“å…¥çš„ç—…ç—‡æè¿°ä¸­æå–ç»“æ„åŒ–ç—‡çŠ¶ä¿¡æ¯ã€‚
**è¯·æ±‚ä½“**ï¼š
```json
{
  "user_input": "å­—ç¬¦ä¸²ï¼Œç—…ç—‡æè¿°",
  "online_model": true
}
```
**å“åº”**ï¼š
- æˆåŠŸï¼š`{"success": true, "data": {ç—‡çŠ¶ç»“æ„åŒ–æ•°æ®}}`
- å¤±è´¥ï¼š`{"success": false, "error": "é”™è¯¯ä¿¡æ¯"}`

#### 3. `POST /select_clinic/` - é€‰æ‹©è¯Šå®¤
**åŠŸèƒ½**ï¼šæ ¹æ®ç»“æ„åŒ–ç—‡çŠ¶ä¿¡æ¯æ¨èåˆé€‚çš„è¯Šå®¤ã€‚
**è¯·æ±‚ä½“**ï¼š
```json
{
  "conditions": {ç—‡çŠ¶ç»“æ„åŒ–æ•°æ®å¯¹è±¡},
  "online_model": true
}
```
**å“åº”**ï¼š
- æˆåŠŸï¼š`{"success": true, "data": {"clinic_selection": "è¯Šå®¤ID"}}`
- å¤±è´¥ï¼š`{"success": false, "error": "é”™è¯¯ä¿¡æ¯"}`

#### 4. `POST /collect_requirement/` - æ”¶é›†ä¸ªæ€§åŒ–éœ€æ±‚
**åŠŸèƒ½**ï¼šä»ç”¨æˆ·è¾“å…¥ä¸­æå–ä¸ªæ€§åŒ–éœ€æ±‚ï¼ˆå¦‚åå¥½ã€é™åˆ¶æ¡ä»¶ç­‰ï¼‰ã€‚
**è¯·æ±‚ä½“**ï¼š
```json
{
  "user_input": "å­—ç¬¦ä¸²ï¼Œéœ€æ±‚æè¿°",
  "online_model": true
}
```
**å“åº”**ï¼š
- æˆåŠŸï¼š`{"success": true, "data": [éœ€æ±‚å¯¹è±¡åˆ—è¡¨]}`
- å¤±è´¥ï¼š`{"success": false, "error": "é”™è¯¯ä¿¡æ¯"}`

#### 5. `POST /patch_route/` - ä¿®æ”¹è·¯çº¿
**åŠŸèƒ½**ï¼šæ ¹æ®ç›®çš„åœ°è¯Šå®¤å’Œéœ€æ±‚æ‘˜è¦ä¿®æ”¹åŸè·¯çº¿ã€‚
**è¯·æ±‚ä½“**ï¼š
```json
{
  "destination_clinic_id": "å­—ç¬¦ä¸²ï¼Œç›®çš„åœ°è¯Šå®¤ID",
  "requirement_summary": [
    {éœ€æ±‚å¯¹è±¡1},
    {éœ€æ±‚å¯¹è±¡2}
  ],
  "origin_route": [
    {"this": "èµ·ç‚¹ä½ç½®ID", "next": "ä¸‹ä¸€ä½ç½®ID"},
    ...
  ],
  "online_model": true
}
```
**å“åº”**ï¼š
- æˆåŠŸï¼š`{"success": true, "data": {ä¿®æ”¹åçš„è·¯çº¿æ•°æ®}}`
- å¤±è´¥ï¼š`{"success": false, "error": "é”™è¯¯ä¿¡æ¯"}`

#### 6. `POST /parse_commands/` - è§£æå°è½¦ç§»åŠ¨æŒ‡ä»¤
**åŠŸèƒ½**ï¼šå°†è·¯çº¿è½¬æ¢ä¸ºå°è½¦å¯æ‰§è¡Œçš„ç§»åŠ¨æŒ‡ä»¤åºåˆ—ã€‚
**è¯·æ±‚ä½“**ï¼š
```json
{
  "origin_route": [
    {"this": "èµ·ç‚¹ä½ç½®ID", "next": "ä¸‹ä¸€ä½ç½®ID"},
    ...
  ]
}
```
**å“åº”**ï¼š
- æˆåŠŸï¼š`{"success": true, "data": {æŒ‡ä»¤åºåˆ—}}`
- å¤±è´¥ï¼š`{"success": false, "error": "é”™è¯¯ä¿¡æ¯"}`

#### å…¬å…±æ•°æ®ç»“æ„ï¼š
- `LocationLink`ï¼š`{"this": "ä½ç½®ID", "next": "ä¸‹ä¸€ä½ç½®ID"}`
- `ConditionCollectorOutput`ï¼šç—‡çŠ¶ç»“æ„åŒ–æ•°æ®ï¼ˆç”± `collect_conditions` ç”Ÿæˆï¼‰
- `Requirement`ï¼šéœ€æ±‚å¯¹è±¡ï¼ˆç”± `collect_requirement` ç”Ÿæˆï¼‰
- `online_model` å‚æ•°ï¼š`true` ä½¿ç”¨åœ¨çº¿ LLMï¼ˆDeepSeekï¼‰ï¼Œ`false` ä½¿ç”¨ç¦»çº¿ LLM

### Voice Interaction API æ¥å£è¯¦æƒ…ï¼ˆåŸºäº `backend/src/router/voice.py`ï¼‰ï¼š

åç«¯è¯­éŸ³äº¤äº’ç³»ç»Ÿæä¾›äº†ä»¥ä¸‹ RESTful API ç«¯ç‚¹ï¼Œæ‰€æœ‰ç«¯ç‚¹å‡ä»¥ `/api/voice/` ä¸ºå‰ç¼€ï¼š

#### 1. `POST /stt` - è¯­éŸ³è½¬æ–‡æœ¬ï¼ˆSpeech-to-Textï¼‰
**åŠŸèƒ½**ï¼šå°†ä¸Šä¼ çš„éŸ³é¢‘æ–‡ä»¶è½¬æ¢ä¸ºæ–‡æœ¬ã€‚
**è¯·æ±‚**ï¼š`multipart/form-data` è¡¨å•ï¼ŒåŒ…å« `file` å­—æ®µï¼ˆWAV éŸ³é¢‘æ–‡ä»¶ï¼‰ã€‚
**å“åº”**ï¼š
- æˆåŠŸï¼š`{"text": "è¯†åˆ«å‡ºçš„æ–‡æœ¬å†…å®¹"}`ï¼ˆJSON æ ¼å¼ï¼‰
- å¤±è´¥ï¼šå¯èƒ½è¿”å› 500 é”™è¯¯æˆ–è¯†åˆ«å¤±è´¥

**ä½¿ç”¨ç¤ºä¾‹**ï¼š
```bash
curl -X POST -F "file=@audio.wav" http://localhost:8000/api/voice/stt
```

#### 2. `GET /tts` - æ–‡æœ¬è½¬è¯­éŸ³ï¼ˆText-to-Speechï¼‰
**åŠŸèƒ½**ï¼šå°†æ–‡æœ¬è½¬æ¢ä¸ºè¯­éŸ³éŸ³é¢‘æ–‡ä»¶ã€‚
**è¯·æ±‚å‚æ•°**ï¼š`text` æŸ¥è¯¢å‚æ•°ï¼ˆè¦è½¬æ¢çš„æ–‡æœ¬å†…å®¹ï¼‰ã€‚
**å“åº”**ï¼šç›´æ¥è¿”å› `audio/wav` æ ¼å¼çš„éŸ³é¢‘æ–‡ä»¶æµï¼Œæ–‡ä»¶åä¸º `output.wav`ã€‚

**ä½¿ç”¨ç¤ºä¾‹**ï¼š
```bash
curl -X GET "http://localhost:8000/api/voice/tts?text=ä½ å¥½ï¼Œæˆ‘æ˜¯æ™ºèƒ½åŠ©æ‰‹" --output speech.wav
```

#### æŠ€æœ¯å®ç°è¯´æ˜ï¼š
- **STT æµç¨‹**ï¼šæ¥æ”¶ WAV æ–‡ä»¶ â†’ ä¿å­˜åˆ° `./assets/input.wav` â†’ è°ƒç”¨ `VoiceInteraction().stt_async()` â†’ è¿”å›è¯†åˆ«æ–‡æœ¬
- **TTS æµç¨‹**ï¼šæ¥æ”¶æ–‡æœ¬ â†’ è°ƒç”¨ `VoiceInteraction().tts_async(text)` â†’ ç”Ÿæˆ WAV æ–‡ä»¶ â†’ è¿”å›éŸ³é¢‘æ–‡ä»¶æµ
- **éŸ³é¢‘æ ¼å¼**ï¼šWAV æ ¼å¼ï¼Œé€‚ç”¨äº Web Audio API æ’­æ”¾

### API Patterns Needed:
- Fetch/Axios integration for HTTP requests
- WebSocket for real-time voice streaming
- Environment variables for API endpoints
- Error handling and loading states

## 8. UI/UX Patterns & Design System

### Key Design Patterns:
1. **Fixed Aspect Container Pattern**:
   - All pages use `FixedAspectContainer` for consistent sizing
   - Default: 300Ã—600px, Planned: 332Ã—774.66px (9:21 aspect ratio)
   - Centered in viewport with overflow detection

2. **Voice Interaction Pattern**:
   - 250ms long-press threshold (prevents accidental activation)
   - Multi-layer visual feedback (FAB styling, overlay, indicators)
   - Smooth fade transitions (0.25s)

3. **Message Bubble Pattern**:
   - Clear role differentiation (left/right alignment, color coding)
   - 80% maximum width constraint
   - Consistent spacing and typography
   - Icon-based sender identification

4. **Responsive Overflow Pattern**:
   - Smart detection of content exceeding viewport
   - Dynamic switching between centered and top-aligned layouts
   - Hidden scrollbars with maintained functionality

### Animation System:
- **CSS Transitions**: 150ms (fast), 300ms (medium), 500ms (slow)
- **Custom Keyframes**: Pulse rings, audio waves, chaos motion
- **Performance Optimized**: `will-change`, `backface-visibility`
- **Hardware Accelerated**: Transform and opacity transitions

### Accessibility Features:
- Semantic HTML structure
- Keyboard navigation support
- Sufficient color contrast (â‰¥4.5:1)
- Screen reader compatibility
- Reduced motion considerations

## 9. Code Quality & Structure

### Strengths:
1. **Modular Architecture**: Clear separation of concerns
2. **Composable Design**: Reusable logic in composables
3. **Consistent Styling**: Tailwind-first approach with design system
4. **Comprehensive Documentation**: Detailed design principles and solved issues
5. **Type Safety**: Prop validation and TypeScript-like patterns

### Areas for Improvement:
1. **Backend API Connectivity**: API service layer implemented but needs actual backend connection and testing
2. **Voice Recognition Integration**: Implementation plan created. Needs Phase 1-5 implementation for voice recording, STT API, skeleton messages, and streaming text display.
3. **Speech Synthesis Integration**: TTS API endpoints defined but not connected to `/api/voice/tts`
4. **Testing Infrastructure**: Still no unit or integration tests (TEST_WORKFLOW.md guide added)
5. **MedicalView Integration**: Medical consultation page still needs workflow system adaptation
6. **Real-time Voice Streaming**: WebSocket implementation for continuous voice interaction pending
7. **Authentication System**: JWT token management not yet implemented
8. **Type Safety Enhancement**: JSDoc comments added but no TypeScript compilation

### File Structure:
```
frontend/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ message-bubbles/     # Four-layer message system
â”‚   â”‚   â”œâ”€â”€ settings/            # Settings page components
â”‚   â”‚   â””â”€â”€ *.vue               # Layout and UI components
â”‚   â”œâ”€â”€ composables/            # Reusable logic (useLongPress, useViewportOverflow, etc.)
â”‚   â”œâ”€â”€ stores/                 # Pinia stores for state management
â”‚   â”‚   â”œâ”€â”€ index.js           # Pinia store registration
â”‚   â”‚   â”œâ”€â”€ workflow.js        # 7-state workflow state machine
â”‚   â”‚   â””â”€â”€ api.js             # API service layer with error handling
â”‚   â”œâ”€â”€ types/                  # JSDoc type definitions
â”‚   â”‚   â””â”€â”€ workflow.js        # Type definitions matching backend Pydantic models
â”‚   â”œâ”€â”€ utils/                  # Utility functions
â”‚   â”‚   â””â”€â”€ route.js           # Route generation and modification utilities
â”‚   â”œâ”€â”€ views/                  # Page components (NavigationView.vue integrated with workflow)
â”‚   â”œâ”€â”€ router/                 # Vue Router configuration
â”‚   â””â”€â”€ style.css              # Global styles
â”œâ”€â”€ docs/                       # Design documentation
â”œâ”€â”€ .env.development           # Development environment variables
â”œâ”€â”€ .env                       # Production environment variables
â””â”€â”€ vite.config.js             # Build configuration
```

## 10. Development Status & Next Steps

### âœ… Completed:
- Core UI/UX implementation
- Voice interaction interface
- Message system architecture
- Routing and navigation
- Settings page
- Design system documentation
- **Four-State Workflow System Implementation**:
  - Complete state machine (`idle` â†’ `collecting_conditions` â†’ `selecting_clinic` â†’ `collecting_requirements` â†’ `patching_route` â†’ `completed` â†’ `error`)
  - Pinia stores for workflow state management (`/src/stores/workflow.js`)
  - API service layer for backend integration (`/src/stores/api.js`)
  - Type definitions matching backend Pydantic models (`/src/types/workflow.js`)
  - Route utility functions for path generation and modification (`/src/utils/route.js`)
  - Environment configuration (`.env`, `.env.development`)
  - Pure voice interaction interface (no text input boxes)
  - Integration with existing `NavigationView.vue`

### ğŸ”„ In Progress:
- **Voice Recognition Integration**: Implementation in progress - detailed plan created for voice recording, STT API, skeleton messages, and streaming text display
- **Workflow System Testing**: End-to-end testing with backend API integration
- **MedicalView Integration**: Applying the same workflow pattern to the medical consultation assistant
- **Error Handling Refinement**: Improving user feedback for API failures and network errors

### â³ Pending Integration:
1. **Voice Recognition API**: Implementation plan ready - includes voice recording, STT API integration, skeleton messages, and streaming text display
2. **Speech Synthesis API**: Connect text-to-speech with backend `/api/voice/tts` endpoint
3. **Actual Backend Connectivity**: Test workflow system with running backend server
4. **Real-time Voice Streaming**: WebSocket implementation for continuous voice interaction
5. **Authentication System**: JWT token management for secure API calls
6. **Cross-view State Synchronization**: Share workflow state between NavigationView and MedicalView
7. **Offline Mode Support**: Mock API responses for development without backend

### Technical Debt (Partially Addressed):
- âœ… **Environment Configuration**: Added `.env` and `.env.development` files with API endpoint configuration
- âœ… **API Service Abstraction**: Created comprehensive API service layer in `/src/stores/api.js` with standardized error handling
- âœ… **Error Handling Framework**: Implemented standardized error handling in workflow and API stores with voice command restart capability
- ğŸ”„ **Hardcoded Conversation Data**: Partially addressed - workflow system uses dynamic messages but initial greetings are static
- ğŸ”„ **Limited Error Recovery**: Basic error states implemented but could be more robust with better user feedback
- â³ **Testing Infrastructure**: Still no unit or integration tests (but added `TEST_WORKFLOW.md` guide for manual testing)
- â³ **Type Safety**: JSDoc comments added but no TypeScript compilation for compile-time validation
- â³ **Code Duplication**: MedicalView.vue still needs workflow integration (NavigationView.vue already integrated)

## 11. Current Testing Status & Validation Methods

### Workflow System Testing Status:
- **âœ… State Machine Logic**: Implemented and functioning with 7-state transitions
- **âœ… Route Processing Utilities**: `generateOriginalRoute()`, `applyPatchesToRoute()`, `validateRouteContinuity()` functions tested
- **âœ… Pinia Store Integration**: `useWorkflowStore()` and `useApiStore()` properly integrated in NavigationView.vue
- **ğŸ”„ API Connectivity**: API service layer ready but STT API has audio format compatibility issues. Other endpoints require testing with running backend server.
- **ğŸ”„ Voice Integration**: STT API connected but has audio format compatibility issues (WebM â†’ WAV conversion needed). TTS API endpoints defined but not connected.

### Manual Testing Checklist:
1. **Build Verification**: Ensure `npm run build` succeeds without errors
2. **Development Server**: Verify `npm run dev` starts on http://localhost:5173
3. **Navigation Page Access**: Access `/nav_page` and verify page loads correctly
4. **Workflow Initialization**: Verify automatic greeting message appears on page load
5. **Voice Interaction UI**: Test 250ms long-press on FAB microphone button shows `VoiceOverlay`
6. **State Transitions**: Manually test workflow progression through API mock responses
7. **Error Recovery**: Test voice command "é‡æ–°å¼€å§‹" to restart workflow from any state

### Backend Integration Testing Requirements:
1. **Start Backend Server**: Ensure backend is running on http://localhost:8000
2. **API Endpoint Verification**: Test `/api/triager/collect_conditions/` endpoint with sample input
3. **CORS Configuration**: Verify backend allows requests from frontend origin (http://localhost:5173)
4. **Environment Variables**: Confirm `VITE_API_BASE_URL` is correctly set in `.env.development`

### Critical Paths for End-to-End Testing:
1. **Symptom Collection Flow**: Voice input â†’ `collect_conditions` API â†’ structured symptom data
2. **Clinic Selection Flow**: Symptom data â†’ `select_clinic` API â†’ `clinic_id` selection
3. **Requirement Collection Flow**: Voice input â†’ `collect_requirement` API â†’ structured requirements
4. **Route Optimization Flow**: Clinic ID + requirements â†’ `patch_route` API â†’ optimized route
5. **Error Handling Flow**: Network failure â†’ graceful error recovery â†’ user retry option

### Testing Tools & Documentation:
- **TEST_WORKFLOW.md**: Step-by-step guide for manual workflow testing
- **Postman/curl**: For backend API endpoint verification
- **Browser DevTools**: For network request inspection and debugging
- **Console Logging**: Workflow store includes detailed console logging for state transitions

## 12. Notable Implementation Details

### Four-State Workflow System Implementation:
- **State Machine Design**: 7-state workflow (`idle` â†’ `collecting_conditions` â†’ `selecting_clinic` â†’ `collecting_requirements` â†’ `patching_route` â†’ `completed` â†’ `error`)
- **Pinia Store Architecture**: Centralized state management in `/src/stores/workflow.js` with computed properties for all states
- **API Service Layer**: Dedicated HTTP client in `/src/stores/api.js` with standardized error handling and loading states
- **Pure Voice Interaction**: No text input boxes - all interaction via long-press microphone button (250ms threshold)
- **Route Processing Pipeline**:
  1. **Base Path**: `entrance â†’ registration_center â†’ <xxx_clinic> â†’ pharmacy â†’ exit`
  2. **Original Route Generation**: Replace `<xxx_clinic>` placeholder with actual `clinic_id`
  3. **Patch Application**: Apply `patches` array to modify route based on user requirements
  4. **Route Validation**: Continuity checking and error detection
- **Type Safety**: JSDoc type definitions in `/src/types/workflow.js` matching backend Pydantic models
- **Environment Configuration**: `.env` files for development and production API endpoints
- **Error Recovery**: Voice command "é‡æ–°å¼€å§‹" to restart workflow from any state

### Custom Shadow System:
```css
/* FAB Button Shadows */
shadow-[0_8px_20px_rgba(0,0,0,0.35)]        /* Default */
hover:shadow-[0_12px_28px_rgba(0,0,0,0.45)] /* Hover */
!shadow-[0_16px_32px_rgba(0,0,0,0.55)]      /* Active */
```

### Animation Performance:
- Uses `transform` and `opacity` for GPU acceleration
- `will-change` for performance hints
- `backface-visibility: hidden` for smoother 3D transforms

### Responsive Strategy:
- Fixed container with overflow detection
- Dynamic vertical alignment based on content height
- Touch-optimized scrolling with hidden scrollbars

### Security Considerations:
- HTTPS requirement for camera access
- No sensitive data in frontend code
- Proper CORS configuration needed for backend APIs

## 13. Voice Interaction API Integration Plan (Draft)

### User Requirements Recap

**Voice Interaction Workflow Specification:**
1. **Voice Capture**: User presses FAB to start voice recording, releases FAB to end recording. Voice binary data is saved for STT processing.
2. **STT API Call**: Send binary audio data to backend `/api/voice/stt` endpoint (multipart/form-data with WAV file).
3. **Skeleton Message Display**: When FAB is released, add a blinking skeleton message to conversation list while waiting for backend response.
4. **Streaming Text Display**: After backend responds, replace skeleton with recognized text content displayed in streaming fashion (character-by-character or word-by-word animation).
5. **Workflow Priority**: Implement voice recognition pipeline first, state transitions will be integrated later.

### Technical Analysis

#### Current State:
- âœ… **Voice UI Framework**: 250ms long-press FAB with `useLongPress(250)` composable
- âœ… **Visual Feedback**: `VoiceOverlay` with `ListeningIndicator` (audio waves + pulsing rings)
- âœ… **Message System**: Four-layer message bubble architecture (MessageBubble â†’ BasicMessageBubble â†’ Assistant/UserMessageBubble)
- âœ… **API Service Layer**: `useApiStore()` with standardized HTTP client and error handling
- â³ **Voice Recording**: No audio capture implementation
- â³ **STT API Integration**: No methods for `/api/voice/stt` endpoint
- â³ **Skeleton Messages**: Message system doesn't support skeleton/loading states
- â³ **Streaming Text Display**: No progressive text reveal animations

#### Backend API Requirements:
- **STT Endpoint**: `POST /api/voice/stt` (multipart/form-data, `file` field with WAV audio)
- **Response Format**: `{"text": "recognized text content"}` (JSON)
- **Audio Format**: WAV format suitable for Web Audio API playback

### Implementation Plan

#### Phase 1: Voice Recording Composable (`/src/composables/useVoiceRecorder.js`)
- Create `useVoiceRecorder()` composable with MediaRecorder API
- Integrate with existing `useLongPress` logic:
  - `start()`: Begin audio recording
  - `end()`: Stop recording and return audio Blob (WAV format)
- Handle browser permissions (getUserMedia)
- Add error handling for microphone access failures

#### Phase 2: STT API Integration (`/src/stores/api.js`)
- Add `speechToText(audioBlob)` method to `useApiStore`
- Implement multipart/form-data upload with `FormData`
- Handle backend response parsing
- Add loading state management for voice recognition
- Extend error handling for audio processing failures

#### Phase 3: Skeleton Message System (`/src/components/message-bubbles/`)
- Extend message type definitions in `/src/types/workflow.js`:
  - Add `isSkeleton: boolean` property
  - Add `isStreaming: boolean` property
  - Add `streamingProgress: number` for progressive display
- Create `SkeletonMessageBubble.vue` component:
  - Blinking animation for loading state
  - Placeholder text or wave indicators
- Modify `MessageBubble.vue` router to handle skeleton messages
- Update `ConversationList.vue` to support new message properties

#### Phase 4: Streaming Text Display (`/src/utils/streaming.js`)
- Create `displayTextStreamingly(element, text, options)` utility
- Implement character-by-character or word-by-word reveal animation
- Configurable speed and easing functions
- Support interruption and completion callbacks
- Integrate with Vue's reactivity system

#### Phase 5: NavigationView Integration (`/src/views/NavigationView.vue`)
- Integrate `useVoiceRecorder` with existing `useLongPress` logic
- Modify `handleVoiceInput()` to:
  1. Capture audio on FAB release
  2. Add skeleton message to conversation
  3. Call `apiStore.speechToText(audioBlob)`
  4. Replace skeleton with streaming text on response
  5. Pass recognized text to workflow system
- Add visual states for recording, processing, and streaming
- Implement error recovery for failed voice recognition

#### Phase 6: Testing and Validation
- Manual testing with mock backend responses
- Audio recording permission testing
- Streaming animation performance testing
- Error scenario testing (no microphone, network failure, etc.)
- Cross-browser compatibility testing (Chrome, Firefox, Safari)

### Technical Considerations

#### Audio Format Compatibility:
- **Backend Expectation**: WAV format (mono, 16kHz recommended)
- **Browser Support**: MediaRecorder with `audio/wav` or `audio/webm` codecs
- **Conversion Needs**: May need `audio/webm` to WAV conversion if browsers don't support WAV directly

#### Performance Optimization:
- **Audio Quality**: Balance between quality and file size (16kHz mono, 16-bit PCM)
- **Streaming Animation**: Use CSS transitions or requestAnimationFrame for smooth text reveal
- **Memory Management**: Clean up audio Blobs after processing to prevent memory leaks

#### User Experience:
- **Visual Feedback**: Clear indication of recording, processing, and streaming states
- **Error Recovery**: Graceful handling of microphone permissions and network failures
- **Accessibility**: Screen reader support for voice interaction states

#### Integration with Workflow System:
- **Message Coordination**: Skeleton messages must integrate with existing workflow message management
- **State Management**: Voice processing states should complement workflow states (idle, processing, completed)
- **Error Propagation**: Voice recognition errors should trigger workflow error state when appropriate

### Success Criteria

1. **Functional Completeness**:
   - User can record voice via 250ms long-press FAB
   - Audio is successfully sent to backend STT API
   - Skeleton message appears during processing
   - Recognized text streams into conversation
   - Error states are handled gracefully

2. **Technical Quality**:
   - Clean separation of concerns (recording, API, UI)
   - Reusable composables and utilities
   - Type-safe data flow with JSDoc
   - Performance-optimized audio processing

3. **User Experience**:
   - Intuitive voice interaction flow
   - Clear visual feedback at all stages
   - Responsive and accessible interface
   - Smooth animations and transitions

### Estimated Timeline

**Phase 1-2 (Voice Recording + API)**: 2-3 hours
**Phase 3-4 (Skeleton + Streaming)**: 2-3 hours
**Phase 5 (Integration)**: 1-2 hours
**Phase 6 (Testing)**: 1-2 hours

**Total Estimated Effort**: 6-10 hours

### Next Steps

1. Begin implementation with Phase 1 (Voice Recording Composable)
2. Test audio capture functionality independently
3. Integrate with existing NavigationView incrementally
4. Validate each phase before proceeding to next
5. Update documentation as implementation progresses

## 14. Summary

The UFC-2026 frontend is a well-architected Vue 3 application with a strong focus on user experience and visual design. It implements a hospital intelligent assistant system with voice interaction, facial recognition login, and dual-mode assistance (navigation and medical).

**Key Strengths**:
- Modern technology stack with best practices (Vue 3.5.25, Vuetify 3.12.0, Tailwind v4.2.0)
- Comprehensive design system and documentation with detailed implementation guides
- Modular, component-based architecture with clear separation of concerns
- **Advanced Workflow System**: Four-state hospital navigation workflow with automatic state transitions
- **Voice-First Interface**: Pure voice interaction design with no text input dependencies
- **Type-Safe Data Flow**: JSDoc type definitions matching backend Pydantic models
- **Robust Error Handling**: Standardized error recovery with voice command restart capability
- Excellent visual design and animations with custom shadow systems
- Responsive and accessible UI patterns with viewport overflow detection

**Integration Requirements**:
- âœ… **State Management Implementation**: Complete Pinia workflow system with 7-state machine
- âœ… **Error Handling Framework**: Standardized error handling in API and workflow stores with voice command restart
- âœ… **Environment Configuration**: `.env` files with API endpoint configuration for development and production
- âœ… **Workflow Logic Implementation**: Complete four-state workflow with automatic transitions and route processing
- ğŸ”„ **Backend API Connectivity**: API service layer implemented but needs actual backend connection and testing
- ğŸ”„ **Voice Recognition Integration**: Implementation plan created for STT API with voice recording, skeleton messages, and streaming text display. Ready for Phase 1 implementation.
- ğŸ”„ **Speech Synthesis Integration**: TTS API endpoints defined but not connected to `/api/voice/tts`
- ğŸ”„ **Testing Infrastructure**: Manual testing guide (`TEST_WORKFLOW.md`) available but no automated tests
- â³ **MedicalView Integration**: Navigation workflow complete but medical consultation page needs adaptation
- â³ **Authentication System**: JWT token management not yet implemented for secure API calls
- â³ **Real-time Voice Streaming**: WebSocket implementation for continuous voice interaction pending

The codebase demonstrates professional frontend development practices and is well-positioned for integration with the backend services described in the project documentation.

## 15. Backend Integration Issues & Solutions (2026-02-26)

### Status Update (2026-02-26): Issue Confirmed

**Actual Error Occurred**: The STT API integration failure predicted in this section has now actually occurred during testing. The exact error matches the analysis:

```
INFO:     127.0.0.1:39332 - "POST /api/voice/stt/ HTTP/1.1" 307 Temporary Redirect
INFO:     127.0.0.1:39332 - "POST /api/voice/stt HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/n1ghts4kura/Desktop/ufc-2026/backend/venv/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py", line 410, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
  File "/home/n1ghts4kura/Desktop/ufc-2026/backend/venv/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 60, in __call__
    return await self.app(scope, receive, send)
  File "/home/n1ghts4kura/Desktop/ufc-2026/backend/venv/lib/python3.10/site-packages/fastapi/applications.py", line 1134, in __call__
    await super().__call__(scope, receive, send)
  File "/home/n1ghts4kura/Desktop/ufc-2026/backend/venv/lib/python3.10/site-packages/starlette/applications.py", line 107, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n1ghts4kura/Desktop/ufc-2026/backend/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 186, in __call__
    raise exc
  File "/home/n1ghts4kura/Desktop/ufc-2026/backend/venv/lib/python3.10/site-packages/starlette/middleware/errors.py", line 164, in __call__
    await self.app(scope, receive, _send)
  File "/home/n1ghts4kura/Desktop/ufc-2026/backend/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 95, in __call__
    await self.simple_response(scope, receive, send, request_headers=headers)
  File "/home/n1ghts4kura/Desktop/ufc-2026/backend/venv/lib/python3.10/site-packages/starlette/middleware/cors.py", line 153, in simple_response
    await self.app(scope, receive, send)
  File "/home/n1ghts4kura/Desktop/ufc-2026/backend/venv/lib/python3.10/site-packages/starlette/middleware/exceptions.py", line 63, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/home/n1ghts4kura/Desktop/ufc-2026/backend/venv/lib/python3.10/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/home/n1ghts4kura/Desktop/ufc-2026/backend/venv/lib/python3.10/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/home/n1ghts4kura/Desktop/ufc-2026/backend/venv/lib/python3.10/site-packages/fastapi/middleware/asyncexitstack.py", line 18, in __call__
    await self.app(scope, receive, send)
  File "/home/n1ghts4kura/Desktop/ufc-2026/backend/venv/lib/python3.10/site-packages/starlette/routing.py", line 716, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/n1ghts4kura/Desktop/ufc-2026/backend/venv/lib/python3.10/site-packages/starlette/routing.py", line 736, in app
    await route.handle(scope, receive, send)
  File "/home/n1ghts4kura/Desktop/ufc-2026/backend/venv/lib/python3.10/site-packages/starlette/routing.py", line 290, in handle
    await self.app(scope, receive, send)
  File "/home/n1ghts4kura/Desktop/ufc-2026/backend/venv/lib/python3.10/site-packages/fastapi/routing.py", line 119, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/home/n1ghts4kura/Desktop/ufc-2026/backend/venv/lib/python3.10/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/home/n1ghts4kura/Desktop/ufc-2026/backend/venv/lib/python3.10/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/home/n1ghts4kura/Desktop/ufc-2026/backend/venv/lib/python3.10/sites-packages/fastapi/routing.py", line 105, in app
    response = await f(request)
  File "/home/n1ghts4kura/Desktop/ufc-2026/backend/venv/lib/python3.10/site-packages/fastapi/routing.py", line 424, in app
    raw_response = await run_endpoint_function(
  File "/home/n1ghts4kura/Desktop/ufc-2026/backend/venv/lib/python3.10/site-packages/fastapi/routing.py", line 312, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/n1ghts4kura/Desktop/ufc-2026/backend/src/router/voice.py", line 32, in stt
    return JSONResponse( content = {"text": await vi.stt_async()} )
  File "/home/n1ghts4kura/Desktop/ufc-2026/backend/src/voice_interaction/voice_interaction.py", line 41, in stt_async
    return await self.speech_recognizer.recognize_async()
  File "/home/n1ghts4kura/Desktop/ufc-2026/backend/src/voice_interaction/speech2text.py", line 52, in recognize_async
    audio, sr = await loop.run_in_executor(None, sf.read, self.audio_path)
  File "/home/n1ghts4kura/.pyenv/versions/3.10.13/lib/python3.10/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/home/n1ghts4kura/Desktop/ufc-2026/backend/venv/lib/python3.10/site-packages/soundfile.py", line 305, in read
    with SoundFile(file, 'r', samplerate, channels,
  File "/home/n1ghts4kura/Desktop/ufc-2026/backend/venv/lib/python3.10/site-packages/soundfile.py", line 690, in __init__
    self._file = self._open(file, mode_int, closefd)
  File "/home/n1ghts4kura/Desktop/ufc-2026/backend/venv/lib/python3.10/site-packages/soundfile.py", line 1265, in _open
    raise LibsndfileError(err, prefix="Error opening {0!r}: ".format(self.name))
soundfile.LibsndfileError: Error opening './assets/input.wav': Format not recognised.
```

**Validation of Root Cause**: The error confirms our analysis:
1. **Audio Format Mismatch**: Frontend sends WebM/Opus audio (browser default) but backend expects WAV format
2. **Incorrect File Extension**: Backend saves file with `.wav` extension regardless of actual format
3. **Library Limitation**: `soundfile` library fails to read non-WAV file with `.wav` extension
4. **Missing Format Detection**: No validation of uploaded file format before processing

**Immediate Action Required**: Implement **Solution 2 (Backend Audio Format Support)** as the most practical approach:
1. Install `pydub` and `python-magic` in backend dependencies
2. Update `voice.py` to detect audio format using magic bytes
3. Convert WebM/Opus to WAV format using `pydub` before processing
4. Add proper error handling for unsupported formats

**Implementation Priority**:
- **High**: Backend format detection and conversion (Solution 2)
- **Medium**: Frontend WAV encoding fallback (Solution 1)
- **Low**: Route path consistency (trailing slash fix)

**Next Steps**: Follow the implementation plan in Phase A (Immediate Backend Fixes).

### ğŸ¯ Implementation Status (2026-02-26)

#### âœ… å·²å®Œæˆçš„ä¿®å¤ï¼š

1. **åç«¯ä¾èµ–æ›´æ–°** (`requirements.txt`):
   - æ·»åŠ äº† `pydub` å’Œ `python-magic` ä¾èµ–
   - å·²å®‰è£…åˆ°è™šæ‹Ÿç¯å¢ƒä¸­

2. **éŸ³é¢‘æ ¼å¼æ£€æµ‹é€»è¾‘** (`voice.py`):
   - ä½¿ç”¨ `magic` åº“æ£€æµ‹éŸ³é¢‘æ–‡ä»¶æ ¼å¼
   - æ”¯æŒæ ¼å¼: WAV, WebM/Matroska/EBML, MP4, OGG/Opus
   - æ·»åŠ äº†è¯¦ç»†çš„æ ¼å¼æ£€æµ‹æ—¥å¿—

3. **éŸ³é¢‘æ ¼å¼è½¬æ¢**:
   - ä½¿ç”¨ `pydub` è¿›è¡ŒéWAVæ ¼å¼åˆ°WAVçš„è½¬æ¢
   - è‡ªåŠ¨è½¬æ¢ä¸º16kHzå•å£°é“æ ¼å¼ï¼ˆç¬¦åˆåç«¯è¦æ±‚ï¼‰
   - æ·»åŠ äº†è½¬æ¢å¤±è´¥çš„é”™è¯¯å¤„ç†

4. **è·¯ç”±å…¼å®¹æ€§**:
   - æ·»åŠ äº† `@voice_router.post("/stt/")` æ”¯æŒå°¾éƒ¨æ–œæ 
   - é¿å…FastAPIçš„307é‡å®šå‘

5. **é”™è¯¯å¤„ç†æ”¹è¿›**:
   - æä¾›æ¸…æ™°çš„æ ¼å¼ä¸æ”¯æŒé”™è¯¯æ¶ˆæ¯
   - WebMè½¬æ¢å¤±è´¥æ—¶æç¤ºffmpegå®‰è£…éœ€æ±‚
   - ç»Ÿä¸€çš„å¼‚å¸¸å¤„ç†å’Œæ—¥å¿—è®°å½•

#### âš ï¸ å½“å‰é™åˆ¶ä¸è¦æ±‚ï¼š

1. **ffmpegä¾èµ–**:
   - `pydub` éœ€è¦ `ffmpeg` æˆ– `avconv` è¿›è¡ŒéŸ³é¢‘æ ¼å¼è½¬æ¢
   - å½“å‰ç³»ç»Ÿæœªå®‰è£…ffmpegï¼ŒéWAVæ ¼å¼è½¬æ¢ä¼šå¤±è´¥
   - **å®‰è£…å‘½ä»¤**: `sudo dnf install ffmpeg` (Fedora) æˆ– `sudo apt-get install ffmpeg` (Ubuntu)

2. **å‰ç«¯æ ¼å¼å…¼å®¹æ€§**:
   - å‰ç«¯ `useVoiceRecorder.js` å°è¯•çš„æ ¼å¼é¡ºåº: `audio/wav`, `audio/webm;codecs=opus`, `audio/webm`, `audio/mp4`
   - æµè§ˆå™¨é€šå¸¸ä¸æ”¯æŒWAVå½•åˆ¶ï¼Œä¼šå›é€€åˆ°WebM/Opus
   - å®‰è£…ffmpegåï¼ŒWebMâ†’WAVè½¬æ¢å°†æ­£å¸¸å·¥ä½œ

#### ğŸ”§ æµ‹è¯•éªŒè¯ï¼š

1. **WAVæ ¼å¼æµ‹è¯•**: âœ… é€šè¿‡
2. **æ ¼å¼æ£€æµ‹é€»è¾‘**: âœ… é€šè¿‡
3. **WebMæ ¼å¼è¯†åˆ«**: âœ… é€šè¿‡ (æ£€æµ‹ä¸º"EBML file")
4. **APIç«¯ç‚¹è®¿é—®**: âœ… é€šè¿‡ (HTTP 200å“åº”)
5. **WebMè½¬æ¢**: âœ… é€šè¿‡ (å®‰è£…ffmpegå)

#### ğŸš¨ æ–°å‘ç°çš„é—®é¢˜ (2026-02-26): STT API å“åº”æ ¼å¼ä¸åŒ¹é…

**é—®é¢˜ç°è±¡**:
- ç”¨æˆ·å°è¯•é•¿æŒ‰è¯­éŸ³è¾“å…¥ï¼Œå‰ç«¯æ˜¾ç¤º `...`ï¼Œç„¶åæ˜¾ç¤º `è¯­éŸ³è¯†åˆ«å¤±è´¥`
- è°ƒè¯•æ—¥å¿—æ˜¾ç¤ºå®Œæ•´æµç¨‹:
  ```
  [API Store] Request successful: {text: 'ä½ å¥½æˆ‘æ˜¯ d'}
  [NavigationView] STT API è°ƒç”¨å¤±è´¥: undefined
  ```

**æ ¹å› åˆ†æ**:
1. **APIå“åº”æ ¼å¼ä¸åŒ¹é…**:
   - åç«¯ `voice.py` è¿”å›ç®€ç•¥æ ¼å¼: `{"text": "è¯†åˆ«çš„æ–‡æœ¬"}`
   - å‰ç«¯ `NavigationView.vue` æ£€æŸ¥ `if (!sttResponse.success)` å¤±è´¥ï¼Œå› ä¸ºå“åº”ä¸­æ²¡æœ‰ `success` å­—æ®µ
   - å‰ç«¯é”™è¯¯å¤„ç†å°†éª¨æ¶å±æ¶ˆæ¯æ›´æ–°ä¸º `"è¯­éŸ³è¯†åˆ«å¤±è´¥ï¼Œè¯·é‡è¯•"`

2. **é‡å¤äº‹ä»¶è§¦å‘é—®é¢˜**:
   - æ—¥å¿—æ˜¾ç¤º `FAB æ¾å¼€ï¼Œç»“æŸè¯­éŸ³å½•åˆ¶` è¢«è§¦å‘äº†ä¸¤æ¬¡
   - ç¬¬äºŒæ¬¡è§¦å‘æ—¶å½•éŸ³å™¨å·²åœæ­¢ï¼Œå¯¼è‡´ `[VoiceRecorder] å½•éŸ³å™¨æœªå¯åŠ¨æˆ–å·²åœæ­¢`
   - å¯èƒ½åŸå› æ˜¯äº‹ä»¶å†’æ³¡æˆ–ç”¨æˆ·å¿«é€Ÿç‚¹å‡»

3. **å‰ç«¯APIå…¼å®¹æ€§**:
   - `api.js` çš„ `request()` æ–¹æ³•æ­£ç¡®è§£æäº† `{text: "..."}` æ ¼å¼
   - ä½† `speechToText()` æ–¹æ³•æ²¡æœ‰è§„èŒƒåŒ–å“åº”æ ¼å¼
   - `NavigationView.vue` çš„ `handlePressEnd` ç¼ºå°‘é˜²æ­¢é‡å¤å¤„ç†çš„å®Œæ•´æ£€æŸ¥

**è§£å†³æ–¹æ¡ˆå®æ–½**:

1. **å‰ç«¯APIå…¼å®¹æ€§ä¿®å¤** (`api.js`):
   ```javascript
   const speechToText = async (audioBlob) => {
     const response = await request('/voice/stt/', { method: 'POST', body: formData })

     // å…¼å®¹ä¸¤ç§æ ¼å¼ï¼š
     // æ ¼å¼1: {text: "recognized text"} (åç«¯å½“å‰æ ¼å¼)
     // æ ¼å¼2: {success: true, data: {text: "recognized text"}} (æ ‡å‡†æ ¼å¼)

     if (response.success === true && response.data && response.data.text) {
       return response
     } else if (response.text) {
       return {
         success: true,
         data: { text: response.text }
       }
     } else {
       return { success: false, error: 'Unknown response format' }
     }
   }
   ```

2. **é˜²æ­¢é‡å¤å¤„ç†** (`NavigationView.vue`):
   ```javascript
   // æ·»åŠ é¢å¤–çš„æ£€æŸ¥
   if (!voiceRecorder.isRecording.value) {
     console.warn('[NavigationView] æ²¡æœ‰æ­£åœ¨è¿›è¡Œçš„å½•éŸ³ï¼Œå¿½ç•¥æ¾å¼€äº‹ä»¶')
     isProcessingVoice.value = false
     return
   }
   ```

3. **ä¿æŒåç«¯å…¼å®¹æ€§**:
   - æ’¤é”€äº†å¯¹ `voice.py` çš„æ ¼å¼ä¿®æ”¹ï¼Œä¿æŒ `{text: "..."}` æ ¼å¼
   - é¿å…ç ´åå…¶ä»–å¯èƒ½ä¾èµ–æ­¤æ ¼å¼çš„å®¢æˆ·ç«¯

**éªŒè¯çŠ¶æ€**:
- âœ… **ffmpegå®‰è£…**: å·²å®Œæˆï¼ŒWebMâ†’WAVè½¬æ¢æ­£å¸¸å·¥ä½œ
- âœ… **éŸ³é¢‘æ ¼å¼å…¼å®¹æ€§**: WebMæ£€æµ‹å’Œè½¬æ¢æˆåŠŸ (46895å­—èŠ‚ï¼Œaudio/webm;codecs=opus)
- âœ… **è¯­éŸ³è¯†åˆ«å‡†ç¡®æ€§**: è¯†åˆ«ç»“æœä¸º `"ä½ å¥½æˆ‘æ˜¯ d"`ï¼ŒåŸºæœ¬å‡†ç¡®
- âœ… **APIå“åº”å¤„ç†**: å‰ç«¯ç°åœ¨èƒ½æ­£ç¡®å¤„ç†ä¸¤ç§æ ¼å¼
- âœ… **é‡å¤äº‹ä»¶å¤„ç†**: æ·»åŠ äº†å½•éŸ³çŠ¶æ€æ£€æŸ¥ï¼Œé˜²æ­¢é‡å¤å¤„ç†
- âš ï¸ **å·¥ä½œæµé›†æˆ**: ç­‰å¾…æµ‹è¯•è¯†åˆ«æ–‡æœ¬ä¼ é€’åˆ°å·¥ä½œæµç³»ç»Ÿçš„æµç¨‹

**æŠ€æœ¯ç»†èŠ‚**:
1. **éŸ³é¢‘å½•åˆ¶**: Chromeæµè§ˆå™¨ä½¿ç”¨ `audio/webm;codecs=opus` æ ¼å¼
2. **æ ¼å¼è½¬æ¢**: åç«¯æ£€æµ‹ä¸ºWebMï¼Œä½¿ç”¨ffmpegè½¬æ¢ä¸ºWAV (16kHz, mono)
3. **è¯­éŸ³è¯†åˆ«**: sherpa_onnxè¿”å› `"ä½ å¥½æˆ‘æ˜¯ d"`ï¼Œè¯†åˆ«åŸºæœ¬å‡†ç¡®
4. **äº‹ä»¶å¤„ç†**: é•¿æŒ‰250msé˜ˆå€¼å·¥ä½œæ­£å¸¸ï¼Œéœ€è¦é˜²æ­¢é‡å¤è§¦å‘

**é¢„æœŸå·¥ä½œæµ**:
1. ç”¨æˆ·é•¿æŒ‰FAB 250ms â†’ å¼€å§‹å½•éŸ³
2. æ¾å¼€FAB â†’ åœæ­¢å½•éŸ³ï¼Œè·å–WebM/OpuséŸ³é¢‘ (çº¦46KB)
3. å‘é€åˆ° `/api/voice/stt/` â†’ åç«¯è½¬æ¢ä¸ºWAV â†’ sherpa_onnxè¯†åˆ«
4. è¿”å› `{text: "è¯†åˆ«çš„æ–‡æœ¬"}` â†’ å‰ç«¯è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
5. æ›´æ–°éª¨æ¶å±æ¶ˆæ¯ä¸ºè¯†åˆ«æ–‡æœ¬ â†’ è°ƒç”¨ `handleVoiceInput()` â†’ å·¥ä½œæµå¤„ç†

**æˆåŠŸæŒ‡æ ‡**:
- è¯­éŸ³è¯†åˆ«æˆåŠŸæ˜¾ç¤ºç”¨æˆ·è¯´è¯å†…å®¹
- è¯†åˆ«æ–‡æœ¬æ­£ç¡®ä¼ é€’åˆ°å››çŠ¶æ€å·¥ä½œæµç³»ç»Ÿ
- æ— é‡å¤äº‹ä»¶æˆ–é”™è¯¯çŠ¶æ€

#### ğŸ“‹ å‰©ä½™ä»»åŠ¡ï¼š

1. **å®‰è£…ffmpeg** (é«˜ä¼˜å…ˆçº§):
   ```bash
   sudo dnf install ffmpeg  # Fedora
   # æˆ–
   sudo apt-get install ffmpeg  # Ubuntu
   ```

2. **éªŒè¯å®Œæ•´å·¥ä½œæµ**:
   - å®‰è£…ffmpegåæµ‹è¯•å‰ç«¯è¯­éŸ³å½•åˆ¶å’Œè¯†åˆ«
   - éªŒè¯WebMâ†’WAVè½¬æ¢è´¨é‡
   - æµ‹è¯•è·¨æµè§ˆå™¨å…¼å®¹æ€§ (Chrome, Firefox, Safari)

3. **å‰ç«¯å¤‡é€‰æ–¹æ¡ˆ** (å¯é€‰):
   - å¦‚æœffmpegå®‰è£…ä¸å¯è¡Œï¼Œè€ƒè™‘å‰ç«¯WAVç¼–ç 
   - ä½¿ç”¨Web Audio APIæ‰‹åŠ¨ç”ŸæˆWAVæ ¼å¼

### Issue: STT API Integration Failure

**Error Log Analysis:**
```
INFO:     127.0.0.1:39332 - "POST /api/voice/stt/ HTTP/1.1" 307 Temporary Redirect
INFO:     127.0.0.1:39332 - "POST /api/voice/stt HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
...
soundfile.LibsndfileError: Error opening './assets/input.wav': Format not recognised.
```

**Root Cause Analysis:**

1. **Route Path Issue**: Frontend sends request to `/api/voice/stt/` (with trailing slash), backend redirects to `/api/voice/stt` (without slash). This is a FastAPI routing behavior but not critical.

2. **Audio Format Compatibility**: Primary issue - Backend expects standard WAV format (16kHz, mono, PCM) but receives incompatible audio format:
   - Frontend's `useVoiceRecorder` tries WAV first, but browsers have limited WAV support via MediaRecorder
   - Most browsers record as `audio/webm` or `audio/ogg` format
   - Backend's `soundfile` library cannot read non-WAV files saved with `.wav` extension

3. **Audio File Validation**: Backend `speech2text.py` reads from hardcoded path `./assets/input.wav` without validation:
   - No format detection or conversion
   - Assumes 16kHz sample rate without resampling support
   - No file corruption handling

**Technical Details:**

#### Backend Voice Pipeline:
1. `voice.py` - Receives raw bytes, saves as `./assets/input.wav`
2. `voice_interaction.py` - Calls `SpeechRecognizer().recognize_async()`
3. `speech2text.py` - Uses `soundfile.read()` to load WAV file, expects 16kHz mono PCM

#### Frontend Audio Capture:
- `useVoiceRecorder.js` tries MIME types: `audio/wav`, `audio/webm;codecs=opus`, `audio/webm`, `audio/mp4`
- Most browsers support `audio/webm` or `audio/webm;codecs=opus`
- Saved Blob has correct MIME type but wrong file extension on backend

### Solutions

#### Solution 1: Frontend Audio Conversion (Recommended)
**Implement WAV encoding in JavaScript** before sending to backend:
- Use `AudioContext` to decode WebM/Opus to raw PCM
- Manually create WAV headers with correct format
- Ensure 16kHz, mono, 16-bit PCM encoding
- Libraries like `wav-encoder` or manual implementation

#### Solution 2: Backend Audio Format Support
**Extend backend to handle multiple formats**:
- Detect actual audio format using `filetype` or `magic` bytes
- Convert to WAV using `pydub` or `ffmpeg`
- Support WebM, OGG, MP3, etc.

#### Solution 3: Hybrid Approach (Immediate Fix)
**Quick fixes for testing**:

1. **Frontend Fix**: Ensure consistent MIME type and add format validation
2. **Backend Fix**: Add audio format detection and conversion
3. **Path Fix**: Update route to accept trailing slash

### Implementation Plan

#### Phase A: Immediate Backend Fixes (Priority)
1. **Route Update**: Add `@voice_router.post("/stt/")` with trailing slash
2. **Audio Validation**: Check file magic bytes before processing
3. **Format Conversion**: Install `pydub` and add WebMâ†’WAV conversion
4. **Error Handling**: Better error messages for unsupported formats

#### Phase B: Frontend Audio Improvements
1. **WAV Encoding**: Implement proper WAV encoding in `useVoiceRecorder`
2. **Format Detection**: Log actual recorded format for debugging
3. **Fallback Strategy**: Try multiple codecs and select most compatible

#### Phase C: End-to-End Testing
1. **Format Testing**: Test with Chrome, Firefox, Safari audio formats
2. **Quality Testing**: Verify 16kHz mono encoding works correctly
3. **Performance Testing**: Measure encoding/decoding latency

### Code Changes Required

#### Backend (`/backend/src/router/voice.py`):
```python
# Add format detection and conversion
import magic  # or filetype
from pydub import AudioSegment

# In stt() function:
file_bytes = await file.read()
file_type = magic.from_buffer(file_bytes[:1024])

if 'WebM' in file_type or 'Matroska' in file_type:
    # Convert WebM to WAV
    audio = AudioSegment.from_file(io.BytesIO(file_bytes), format="webm")
    audio = audio.set_frame_rate(16000).set_channels(1)
    audio.export(input_wav_path, format="wav")
elif 'WAV' in file_type:
    # Direct save
    with open(input_wav_path, "wb") as f:
        f.write(file_bytes)
else:
    raise HTTPException(400, f"Unsupported audio format: {file_type}")
```

#### Frontend (`/src/composables/useVoiceRecorder.js`):
```javascript
// Add WAV encoding function
async function encodeAsWav(audioBlob) {
  // Decode using Web Audio API
  const arrayBuffer = await audioBlob.arrayBuffer()
  const audioContext = new AudioContext()
  const audioBuffer = await audioContext.decodeAudioData(arrayBuffer)

  // Convert to 16kHz mono, 16-bit PCM
  // Create WAV headers and data
  // Return new Blob with 'audio/wav' MIME type
}
```

### Testing Steps

1. **Install Dependencies**:
   ```bash
   cd backend
   pip install python-magic pydub
   ```

2. **Test Backend Fix**:
   ```bash
   curl -X POST -F "file=@test.webm" http://localhost:8000/api/voice/stt
   ```

3. **Test Frontend Integration**:
   - Record voice in browser
   - Check network tab for request/response
   - Verify audio format in backend logs

### Success Criteria

1. âœ… Backend accepts WebM/Opus/WAV formats
2. âœ… Frontend records and sends compatible audio
3. âœ… STT returns accurate text recognition
4. âœ… Error handling for unsupported formats
5. âœ… Cross-browser compatibility (Chrome, Firefox, Safari)

### Timeline Estimate
- **Phase A (Backend Fix)**: 2-3 hours
- **Phase B (Frontend Improvement)**: 3-4 hours
- **Phase C (Testing)**: 1-2 hours
- **Total**: 6-9 hours

### Next Actions
1. Implement backend audio format detection and conversion
2. Test with sample WebM/WAV files using curl
3. Update frontend to log actual audio format
4. Deploy fixes and run end-to-end tests

## 16. CORS Issue with select_clinic Endpoint (2026-02-26)

### Problem Description
User reports duplicate voice input messages and "Failed to fetch" error. Debugging reveals:

**Symptoms:**
1. Two "æˆ‘æœ‰ç‚¹å¤´ç–¼" user messages appear in conversation
2. Assistant responds with "å·²åˆ†æä½ çš„ç—‡çŠ¶:å¤´ç–¼..."
3. Then "Failed to fetch" error appears

**Root Cause Analysis:**
1. **Duplicate User Messages**: Fixed by modifying `processUserInput()` in workflow.js to check for duplicate user messages
2. **CORS Issue**: The `select_clinic` API endpoint has CORS policy problems:
   - `collect_conditions` endpoint works fine (returns 200 OK with CORS headers)
   - `select_clinic` endpoint blocked by CORS: `No 'Access-Control-Allow-Origin' header is present on the requested resource`

**Console Error:**
```
Access to fetch at 'http://localhost:8000/api/triager/select_clinic/' from origin 'http://localhost:5173'
has been blocked by CORS policy: No 'Access-Control-Allow-Origin' header is present on the requested resource.
```

**Testing Results:**
- `POST /api/triager/collect_conditions/` â†’ âœ… 200 OK with proper CORS headers
- `POST /api/triager/select_clinic/` â†’ âŒ CORS error, "Failed to fetch"

### Possible Causes
1. **Backend Route Missing**: `select_clinic` endpoint might not be properly defined in backend router
2. **CORS Middleware Issue**: CORS middleware might not be applied to all routes or might have configuration issues
3. **Server Error**: `select_clinic` endpoint might return server error (500) without CORS headers
4. **Route Path Mismatch**: Possible trailing slash issue or incorrect route path

### Debugging Steps Taken
1. Added duplicate message prevention in `workflow.js`:
   ```javascript
   // Check if the last message is a user message with the same content
   const isDuplicateUserMessage = lastMessage &&
     lastMessage.name === 'user' &&
     lastMessage.message === userInput &&
     lastMessage.isSkeleton === false

   // Only add user message if it's not a duplicate
   if (!isDuplicateUserMessage) {
     addUserMessage(userInput)
   }
   ```
2. Added detailed logging to `handleConditionsInput()` for API debugging
3. Tested backend endpoints directly via browser console fetch()
4. Identified CORS issue with `select_clinic` endpoint

### Required Fixes
1. **Backend CORS Configuration**: Ensure CORS headers are properly set for all endpoints, including error responses
2. **Backend Route Verification**: Check if `select_clinic` endpoint is correctly implemented in `backend/src/router/triager.py`
3. **Error Handling**: Improve error handling in `autoSelectClinic()` to provide better user feedback

### Immediate Actions
1. Check backend `triager.py` router for `select_clinic` endpoint implementation
2. Verify CORS middleware configuration in backend
3. Test backend directly with curl to see if endpoint exists and returns proper headers
4. If endpoint missing, implement it or fix the route definition

## 17. CORS Issue Resolution (2026-02-26)

### âœ… Problem Resolved
**Issue**: `select_clinic` endpoint had CORS policy blocking frontend requests

**Root Cause**: CORS middleware in `backend/src/main.py` needed enhanced configuration with proper headers

**Solution Implemented**:
1. **Enhanced CORS Configuration** in `backend/src/main.py`:
   ```python
   app.add_middleware(
       CORSMiddleware,
       allow_origins=["*"],  # Allow all origins in development
       allow_credentials=True,
       allow_methods=["*"],
       allow_headers=["*"],
       expose_headers=["*"],  # Expose all response headers
       max_age=600,  # Preflight cache time
   )
   ```
2. **Server Restart**: Backend server needed restart for CORS configuration to take effect
3. **Frontend Duplicate Message Fix**: Added duplicate message prevention in `workflow.js`

### Verification Results
After backend server restart:
- `POST /api/triager/collect_conditions/` â†’ âœ… Works with CORS headers
- `POST /api/triager/select_clinic/` â†’ âœ… Now works with CORS headers
- **Full workflow integration**: Voice input â†’ STT â†’ Condition collection â†’ Clinic selection now functional

### Lessons Learned
1. **CORS Configuration**: Must include `expose_headers=["*"]` for proper header exposure
2. **Server Restart Required**: CORS middleware changes require server restart
3. **Error Response Headers**: 500 errors may not include CORS headers without proper middleware configuration
4. **Duplicate Message Prevention**: Voice input workflow needed duplicate message checking when updating skeleton messages

### Current Status
- âœ… CORS issue resolved
- âœ… Voice input workflow fully functional
- âœ… Four-state workflow system operational
- âœ… Backend and frontend integration complete
- âœ… Git commit created: "ä¿®å¤CORSé—®é¢˜å¹¶å®Œå–„è¯­éŸ³è¾“å…¥å·¥ä½œæµé›†æˆ"

### Remaining Tasks
1. Test complete voice interaction flow with actual microphone input
2. Add streaming text animation for recognized speech
3. Integrate text-to-speech with `/api/voice/tts` endpoint
4. Adapt workflow system for MedicalView.vue

## 18. éº¦å…‹é£æƒé™ç®¡ç†åŠŸèƒ½å®ç° (2026-02-26)

### é—®é¢˜èƒŒæ™¯
ç”¨æˆ·åœ¨ç§»åŠ¨è®¾å¤‡ï¼ˆMicrosoft Edge on Androidï¼‰ä¸Šè®¿é—®åº”ç”¨æ—¶ï¼Œé•¿æŒ‰FABæ— æ³•è§¦å‘å½•éŸ³åŠŸèƒ½ã€‚æ ¸å¿ƒé—®é¢˜æ˜¯éº¦å…‹é£æƒé™è¯·æ±‚æ—¶æœºä¸å½“å’Œæƒé™çŠ¶æ€ç®¡ç†ç¼ºå¤±ã€‚

### è§£å†³æ–¹æ¡ˆ
åœ¨è®¾ç½®é¡µé¢æ·»åŠ éº¦å…‹é£æƒé™ç®¡ç†åŠŸèƒ½ï¼š

1. **UIé›†æˆ**ï¼šåœ¨SettingsView.vueä¸­æ·»åŠ "æƒé™è®¾ç½®"åŒºåŸŸ
2. **äº¤äº’è®¾è®¡**ï¼šä½¿ç”¨SettingsItemç»„ä»¶ï¼Œç‚¹å‡»è§¦å‘æƒé™è¯·æ±‚
3. **ç»“æœåé¦ˆ**ï¼šä½¿ç”¨alert()æ˜ç¡®å‘ŠçŸ¥ç”¨æˆ·æƒé™è¯·æ±‚ç»“æœ

### å®ç°è¯¦æƒ…
- **ç»„ä»¶é€‰æ‹©**ï¼šä½¿ç”¨SettingsItemè€ŒéSettingsSlideræˆ–SettingsToggle
- **æƒé™è¯·æ±‚**ï¼šç›´æ¥è°ƒç”¨getUserMedia({ audio: true })ï¼Œç¬¦åˆæµè§ˆå™¨"ç”¨æˆ·æ‰‹åŠ¿ç›´æ¥è§¦å‘"è¦æ±‚
- **é”™è¯¯å¤„ç†**ï¼šæ ¹æ®é”™è¯¯ç±»å‹æä¾›ä¸åŒçš„ç”¨æˆ·æç¤º
- **çŠ¶æ€ç®¡ç†**ï¼šä¸ä¿å­˜æƒé™çŠ¶æ€ï¼Œæ¯æ¬¡ç‚¹å‡»é‡æ–°è¯·æ±‚

### æŠ€æœ¯è¦ç‚¹
1. **æµè§ˆå™¨å…¼å®¹æ€§**ï¼šæ£€æŸ¥navigator.mediaDevices.getUserMediaæ”¯æŒ
2. **æƒé™ç”Ÿå‘½å‘¨æœŸ**ï¼šè·å–æƒé™åç«‹å³åœæ­¢MediaStreamï¼Œé¿å…å ç”¨éº¦å…‹é£
3. **é”™è¯¯åˆ†ç±»**ï¼šåŒºåˆ†NotAllowedErrorã€NotFoundErrorã€NotReadableErrorç­‰

### ç”¨æˆ·æµç¨‹
1. ç”¨æˆ·è¿›å…¥è®¾ç½®é¡µé¢
2. åœ¨"æƒé™è®¾ç½®"åŒºç‚¹å‡»"éº¦å…‹é£æƒé™"
3. æµè§ˆå™¨å¼¹å‡ºæƒé™è¯·æ±‚å¯¹è¯æ¡†
4. ç”¨æˆ·å…è®¸/æ‹’ç»åï¼Œåº”ç”¨æ˜¾ç¤ºå¯¹åº”æç¤º
5. ç”¨æˆ·çŸ¥æ™“å½“å‰éº¦å…‹é£è®¿é—®çŠ¶æ€

## 19. Nginx HTTPS ä»£ç†é…ç½®å®ç° (2026-02-26)

### é—®é¢˜èƒŒæ™¯
ç”¨æˆ·åœ¨ç§»åŠ¨è®¾å¤‡ï¼ˆMicrosoft Edge on Androidï¼‰ä¸Šè®¿é—®åº”ç”¨æ—¶ï¼Œéº¦å…‹é£è®¿é—®éœ€è¦HTTPSåè®®ã€‚å¼€å‘ç¯å¢ƒé€šå¸¸ä½¿ç”¨HTTPï¼Œå¯¼è‡´éº¦å…‹é£æƒé™è¯·æ±‚å¤±è´¥ã€‚éœ€è¦å°†å‰ç«¯å¼€å‘æœåŠ¡å™¨é…ç½®ä¸ºHTTPSè®¿é—®ä»¥å¯ç”¨è·¨åŸŸéº¦å…‹é£è®¿é—®ã€‚

### è§£å†³æ–¹æ¡ˆ
ä½¿ç”¨Nginxåå‘ä»£ç†å°†æœ¬åœ°HTTPå¼€å‘æœåŠ¡å™¨ï¼ˆlocalhost:5173ï¼‰æš´éœ²ä¸ºHTTPSæœåŠ¡ï¼ˆlocalhost:9000ï¼‰ã€‚

### å®ç°æ–‡ä»¶

#### 1. Nginx é…ç½®æ–‡ä»¶
**æ–‡ä»¶ä½ç½®**: `/home/n1ghts4kura/Desktop/ufc-2026/nginx.example.conf`

**æ ¸å¿ƒåŠŸèƒ½**:
- ç›‘å¬HTTPSç«¯å£ `9000`ï¼Œè‡ªåŠ¨å°†HTTPè¯·æ±‚é‡å®šå‘åˆ°HTTPS
- ä»£ç†æ‰€æœ‰è¯·æ±‚åˆ°Viteå¼€å‘æœåŠ¡å™¨ `localhost:5173`
- æ”¯æŒVue Router historyæ¨¡å¼
- åŒ…å«WebSocketä»£ç†ï¼Œæ”¯æŒViteçƒ­æ¨¡å—æ›¿æ¢ï¼ˆHMRï¼‰
- å¯é€‰çš„åç«¯APIä»£ç†ï¼ˆæ³¨é‡ŠçŠ¶æ€ï¼‰
- æ”¯æŒè‡ªå®šä¹‰Nginxå®‰è£…çš„MIMEç±»å‹é…ç½®

**å…³é”®é…ç½®**:
```nginx
# HTTPSæœåŠ¡å™¨ - ä¸»å¼€å‘ä»£ç†
server {
    listen       9000 ssl;
    # å…è®¸é€šè¿‡IPåœ°å€æˆ–localhostè®¿é—®
    server_name  localhost _;

    # è‡ªç­¾åSSLè¯ä¹¦
    ssl_certificate      /home/n1ghts4kura/ssl/selfsigned.crt;
    ssl_certificate_key  /home/n1ghts4kura/ssl/selfsigned.key;

    # ä»£ç†åˆ°Viteå¼€å‘æœåŠ¡å™¨
    location / {
        proxy_pass http://localhost:5173;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-Proto $scheme;

        # WebSocketæ”¯æŒ
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
    }
}
```

**MIMEç±»å‹é…ç½®é€‰é¡¹**:
1. **è‡ªå®šä¹‰mime.typesæ–‡ä»¶**:
   ```nginx
   include /home/n1ghts4kura/global_nginx/conf/mime.types;
   ```
2. **å†…ç½®æœ€å°åŒ–MIMEç±»å‹**ï¼ˆé…ç½®æ–‡ä»¶å·²åŒ…å«ï¼‰

#### 2. SSLè¯ä¹¦ç”Ÿæˆè„šæœ¬
**æ–‡ä»¶ä½ç½®**: `/home/n1ghts4kura/Desktop/ufc-2026/generate-ssl-cert.sh`

**åŠŸèƒ½**:
- è‡ªåŠ¨åˆ›å»ºè‡ªç­¾åSSLè¯ä¹¦ï¼ˆæœ‰æ•ˆæœŸ365å¤©ï¼‰
- è®¾ç½®æ­£ç¡®çš„æ–‡ä»¶æƒé™ï¼ˆå¯†é’¥600ï¼Œè¯ä¹¦644ï¼‰
- æ”¯æŒ `localhost`ã€`127.0.0.1`å’Œ`0.0.0.0`åŸŸå

**é‡è¦æç¤º**:
- è„šæœ¬ä½¿ç”¨`sudo`è¿è¡Œï¼Œ`$HOME`ç¯å¢ƒå˜é‡ä¼šå˜ä¸º`/root`
- **å¿…é¡»ç¼–è¾‘è„šæœ¬ä¸­çš„è·¯å¾„**ï¼šå°†`/home/n1ghts4kura`æ›¿æ¢ä¸ºå®é™…ä¸»ç›®å½•è·¯å¾„
- è·¯å¾„å®šä¹‰åœ¨è„šæœ¬ç¬¬16è¡Œï¼š`SSL_DIR="/home/n1ghts4kura/ssl"`

#### 3. é…ç½®æŒ‡å—æ–‡æ¡£
**æ–‡ä»¶ä½ç½®**: `/home/n1ghts4kura/Desktop/ufc-2026/frontend/docs/nginx_configuration_guide.md`

**å†…å®¹**: å®Œæ•´çš„å®‰è£…ã€é…ç½®ã€ä½¿ç”¨å’Œæ•…éšœæ’é™¤æŒ‡å—ã€‚

### å‰ç«¯è·¯ç”±éªŒè¯
**æ–‡ä»¶ä½ç½®**: `/home/n1ghts4kura/Desktop/ufc-2026/frontend/src/router/index.js`

**éªŒè¯ç»“æœ**: å‰ç«¯å·²ä½¿ç”¨`createWebHistory()`æ¨¡å¼ï¼Œæ— éœ€ä¿®æ”¹ï¼š
```javascript
const router = createRouter({
  history: createWebHistory(import.meta.env.BASE_URL),  // âœ… å·²ç»æ˜¯historyæ¨¡å¼
  routes: [...]
})
```

### é‡åˆ°çš„é—®é¢˜ä¸è§£å†³æ–¹æ¡ˆ

#### é—®é¢˜1: ERR_SSL_PROTOCOL_ERROR é”™è¯¯
**ç°è±¡**: è®¿é—®`https://<ip>:9000`æ—¶æ˜¾ç¤ºSSLåè®®é”™è¯¯

**åŸå› åˆ†æ**:
1. è¯ä¹¦ä»…åŒ…å«`localhost`å’Œ`127.0.0.1`çš„SANï¼ˆSubject Alternative Nameï¼‰
2. Nginxçš„`server_name`ä»…é…ç½®ä¸º`localhost`
3. é€šè¿‡IPåœ°å€è®¿é—®æ—¶ï¼ŒSSLè¯ä¹¦éªŒè¯å¤±è´¥

**è§£å†³æ–¹æ¡ˆ**:
1. **æ›´æ–°Nginxé…ç½®**: å°†`server_name`æ”¹ä¸º`localhost _`ï¼Œæ”¯æŒé€šé…ç¬¦
2. **æ›´æ–°è¯ä¹¦ç”Ÿæˆè„šæœ¬**: æ·»åŠ `0.0.0.0`åˆ°SANæ‰©å±•ä¸­

#### é—®é¢˜2: 403 Forbidden é™æ€èµ„æºé”™è¯¯
**ç°è±¡**: æµè§ˆå™¨ç©ºç™½ï¼Œæ§åˆ¶å°æ˜¾ç¤ºé™æ€èµ„æºï¼ˆJSã€CSSã€å›¾æ ‡ï¼‰åŠ è½½å¤±è´¥ï¼ŒHTTPçŠ¶æ€ç 403

**åŸå› åˆ†æ**:
1. ç¼ºå°‘MIMEç±»å‹é…ç½®ï¼ŒNginxæ— æ³•æ­£ç¡®è¯†åˆ«æ–‡ä»¶ç±»å‹
2. é™æ€èµ„æºè·¯å¾„æœªæ­£ç¡®ä»£ç†åˆ°Viteå¼€å‘æœåŠ¡å™¨

**è§£å†³æ–¹æ¡ˆ**:
1. **æ·»åŠ MIMEç±»å‹é…ç½®**: åœ¨`http`å—ä¸­æ·»åŠ `types`å®šä¹‰æˆ–`include mime.types`
2. **æ·»åŠ é™æ€èµ„æºä»£ç†**: ä¸ºå¸¸è§é™æ€æ–‡ä»¶æ‰©å±•åæ·»åŠ `location`å—ï¼Œä»£ç†åˆ°ViteæœåŠ¡å™¨

#### é—®é¢˜3: è‡ªå®šä¹‰Nginxå®‰è£…çš„MIMEç±»å‹è·¯å¾„
**ç°è±¡**: ç”¨æˆ·ä½¿ç”¨è‡ªå®šä¹‰ç¼–è¯‘å®‰è£…çš„Nginxï¼Œæ ‡å‡†è·¯å¾„`/etc/nginx/mime.types`ä¸å­˜åœ¨

**è§£å†³æ–¹æ¡ˆ**:
1. **æ–¹æ¡ˆA**: ä½¿ç”¨è‡ªå®šä¹‰`mime.types`æ–‡ä»¶ï¼Œæ·»åŠ `include`æŒ‡ä»¤
2. **æ–¹æ¡ˆB**: ä½¿ç”¨å†…ç½®æœ€å°åŒ–MIMEç±»å‹å®šä¹‰ï¼ˆé…ç½®æ–‡ä»¶å·²åŒ…å«ï¼‰

### è‡ªå®šä¹‰Nginxå®‰è£…é…ç½®

#### æŸ¥æ‰¾mime.typesæ–‡ä»¶
```bash
find ~ -name "mime.types" 2>/dev/null | grep nginx
```

#### é…ç½®ç¤ºä¾‹
```nginx
# ä½¿ç”¨è‡ªå®šä¹‰mime.typesæ–‡ä»¶
include /home/n1ghts4kura/global_nginx/conf/mime.types;
```

### é…ç½®æ­¥éª¤æ€»ç»“

#### 1. å‡†å¤‡é…ç½®æ–‡ä»¶
```bash
cd /home/n1ghts4kura/Desktop/ufc-2026
cp nginx.example.conf nginx.conf
```

#### 2. ç¼–è¾‘nginx.conf
- æ‰¾åˆ°ç¬¬66-67è¡Œçš„`ssl_certificate`å’Œ`ssl_certificate_key`é…ç½®
- å°†`/home/n1ghts4kura`æ›¿æ¢ä¸ºå®é™…ä¸»ç›®å½•è·¯å¾„
- å¦‚éœ€ä½¿ç”¨è‡ªå®šä¹‰mime.typesæ–‡ä»¶ï¼Œå–æ¶ˆæ³¨é‡Š`include`æŒ‡ä»¤å¹¶è®¾ç½®æ­£ç¡®è·¯å¾„

#### 3. ç”ŸæˆSSLè¯ä¹¦
```bash
# å…ˆç¼–è¾‘è„šæœ¬ä¸­çš„è·¯å¾„
vim generate-ssl-cert.sh  # ä¿®æ”¹ç¬¬16è¡ŒSSL_DIRè·¯å¾„

# æ·»åŠ æ‰§è¡Œæƒé™å¹¶è¿è¡Œ
chmod +x generate-ssl-cert.sh
sudo ./generate-ssl-cert.sh
```

#### 4. å¯åŠ¨NginxæœåŠ¡
```bash
# æµ‹è¯•é…ç½®æ–‡ä»¶è¯­æ³•
sudo nginx -c /home/n1ghts4kura/Desktop/ufc-2026/nginx.conf -t

# å¯åŠ¨Nginx
sudo nginx -c /home/n1ghts4kura/Desktop/ufc-2026/nginx.conf

# æ£€æŸ¥è¿è¡ŒçŠ¶æ€
ps aux | grep nginx
sudo netstat -tlnp | grep :9000
```

#### 5. å¯åŠ¨å‰ç«¯å¼€å‘æœåŠ¡å™¨
```bash
cd frontend
npm run dev
```

### è®¿é—®æ–¹å¼

#### 1. æµè§ˆå™¨è®¿é—®
- åœ°å€: **https://localhost:9000** æˆ– **https://<å±€åŸŸç½‘IP>:9000**
- é¦–æ¬¡è®¿é—®ä¼šæ˜¾ç¤ºå®‰å…¨è­¦å‘Šï¼ˆè‡ªç­¾åè¯ä¹¦çš„æ­£å¸¸ç°è±¡ï¼‰
- ç‚¹å‡»"é«˜çº§" â†’ "ç»§ç»­å‰å¾€localhostï¼ˆä¸å®‰å…¨ï¼‰"

#### 2. éº¦å…‹é£æƒé™æµ‹è¯•
1. è¿›å…¥è®¾ç½®é¡µé¢ â†’ ç‚¹å‡»"éº¦å…‹é£æƒé™"æŒ‰é’®
2. æµè§ˆå™¨åº”æ­£å¸¸å¼¹å‡ºéº¦å…‹é£æƒé™è¯·æ±‚å¯¹è¯æ¡†
3. æˆæƒåå³å¯ä½¿ç”¨è¯­éŸ³åŠŸèƒ½

#### 3. è·¯ç”±æµ‹è¯•
- è®¿é—®`https://localhost:9000/settings`ï¼ˆåº”æ­£å¸¸å·¥ä½œï¼Œæ— `#`ç¬¦å·ï¼‰
- ä½¿ç”¨åº•éƒ¨å¯¼èˆªæ åˆ‡æ¢é¡µé¢ï¼ˆåº”ä¿æŒå†å²è®°å½•ï¼‰
- æµè§ˆå™¨åé€€/å‰è¿›æŒ‰é’®åº”æ­£å¸¸å·¥ä½œ

### æŠ€æœ¯è¦ç‚¹

#### 1. HTTPSè¦æ±‚
- æµè§ˆå™¨å®‰å…¨ç­–ç•¥è¦æ±‚éº¦å…‹é£è®¿é—®å¿…é¡»é€šè¿‡HTTPSåè®®
- å¼€å‘ç¯å¢ƒé€šå¸¸ä½¿ç”¨HTTPï¼Œéœ€è¦Nginxä»£ç†æä¾›HTTPSè®¿é—®

#### 2. Vue Router Historyæ¨¡å¼
- å‰ç«¯å·²æ­£ç¡®é…ç½®`createWebHistory()`
- Nginxä»£ç†éœ€è¦æ­£ç¡®å¤„ç†æ‰€æœ‰è·¯ç”±è¯·æ±‚ï¼Œå›é€€åˆ°`index.html`

#### 3. è·¨åŸŸéº¦å…‹é£è®¿é—®
- HTTPSè§£å†³äº†è·¨åŸŸéº¦å…‹é£è®¿é—®çš„å®‰å…¨é™åˆ¶
- æµè§ˆå™¨å®‰å…¨ç­–ç•¥è¦æ±‚"ç”¨æˆ·æ‰‹åŠ¿ç›´æ¥è§¦å‘"æƒé™è¯·æ±‚

#### 4. è‡ªç­¾åè¯ä¹¦
- å¼€å‘ç¯å¢ƒä½¿ç”¨è‡ªç­¾åè¯ä¹¦ï¼Œæµè§ˆå™¨ä¼šæ˜¾ç¤ºå®‰å…¨è­¦å‘Š
- å¯æ·»åŠ åˆ°ç³»ç»Ÿä¿¡ä»»åˆ—è¡¨ä»¥é¿å…è­¦å‘Šï¼ˆç”Ÿäº§ç¯å¢ƒåº”ä½¿ç”¨å—ä¿¡ä»»çš„CAè¯ä¹¦ï¼‰

### éªŒè¯æŒ‡æ ‡

#### 1. åŠŸèƒ½éªŒè¯
- âœ… é€šè¿‡HTTPSè®¿é—®åº”ç”¨
- âœ… é™æ€èµ„æºæ­£ç¡®åŠ è½½ï¼ˆJSã€CSSã€å›¾æ ‡ï¼‰
- âœ… éº¦å…‹é£æƒé™è¯·æ±‚æ­£å¸¸å¼¹å‡º
- âœ… Vue Routerå†å²æ¨¡å¼æ­£å¸¸å·¥ä½œ

#### 2. æŠ€æœ¯éªŒè¯
- âœ… Nginxé…ç½®æ–‡ä»¶è¯­æ³•æ­£ç¡®
- âœ… SSLè¯ä¹¦ç”Ÿæˆå’Œé…ç½®æ­£ç¡®
- âœ… ä»£ç†é…ç½®æ­£ç¡®è½¬å‘åˆ°Viteå¼€å‘æœåŠ¡å™¨
- âœ… WebSocketä»£ç†æ”¯æŒViteçƒ­æ¨¡å—æ›¿æ¢

#### 3. å…¼å®¹æ€§éªŒè¯
- âœ… æ”¯æŒé€šè¿‡localhostå’ŒIPåœ°å€è®¿é—®
- âœ… æ”¯æŒè‡ªå®šä¹‰Nginxå®‰è£…è·¯å¾„
- âœ… æ”¯æŒå¤šæµè§ˆå™¨HTTPSè®¿é—®

### åç»­ä¼˜åŒ–å»ºè®®

#### 1. ç”Ÿäº§ç¯å¢ƒé…ç½®
- ä½¿ç”¨å—ä¿¡ä»»çš„CAç­¾å‘è¯ä¹¦ï¼ˆå¦‚Let's Encryptï¼‰
- è°ƒæ•´é™æ€æ–‡ä»¶æœåŠ¡ä¸ºç›´æ¥æä¾›æ„å»ºäº§ç‰©
- æ·»åŠ å®‰å…¨æ€§å¤´éƒ¨å’Œæ€§èƒ½ä¼˜åŒ–é…ç½®

#### 2. å¼€å‘ä½“éªŒä¼˜åŒ–
- æ·»åŠ è„šæœ¬è‡ªåŠ¨åŒ–è¯ä¹¦ç”Ÿæˆå’ŒNginxå¯åŠ¨
- æ·»åŠ ç¯å¢ƒæ£€æµ‹å’Œé…ç½®éªŒè¯
- æä¾›ä¸€é”®å¯åŠ¨å¼€å‘ç¯å¢ƒçš„è„šæœ¬

#### 3. ç§»åŠ¨è®¾å¤‡ä¼˜åŒ–
- æµ‹è¯•ç§»åŠ¨æµè§ˆå™¨HTTPSå…¼å®¹æ€§
- ä¼˜åŒ–ç§»åŠ¨ç«¯éº¦å…‹é£æƒé™è¯·æ±‚æµç¨‹
- æ·»åŠ ç§»åŠ¨è®¾å¤‡ç‰¹å®šé…ç½®æç¤º

### ç›¸å…³æ–‡ä»¶
| æ–‡ä»¶ | ç”¨é€” | ä½ç½® |
|------|------|------|
| `nginx.example.conf` | Nginxä¸»é…ç½®æ–‡ä»¶ | é¡¹ç›®æ ¹ç›®å½• |
| `generate-ssl-cert.sh` | SSLè¯ä¹¦ç”Ÿæˆè„šæœ¬ | é¡¹ç›®æ ¹ç›®å½• |
| `nginx_configuration_guide.md` | å®Œæ•´é…ç½®æŒ‡å— | `frontend/docs/` |
| `router/index.js` | Vue Routeré…ç½® | `frontend/src/router/` |
| `vite.config.js` | Viteæ„å»ºé…ç½® | `frontend/` |